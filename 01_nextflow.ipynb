{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff50791b",
   "metadata": {},
   "source": [
    "# **Sample Processing – Nextflow Assembly Pipeline (GHRU)**\n",
    "\n",
    "For the processing of samples obtained after Illumina sequencing, the **GHRU assembly pipeline** was used. This notebook documents the **inputs, execution steps, parameters, and expected outputs** of the pipeline.\n",
    "\n",
    "The workflow is implemented using **Nextflow**, ensuring reproducibility and scalability across multiple samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe25053",
   "metadata": {},
   "source": [
    "## Pipeline Description\n",
    "\n",
    "The GHRU assembly pipeline is a Nextflow-based workflow designed for **short-read whole-genome assembly**. It performs genome assembly and generates quality-controlled outputs suitable for downstream genomic analyses.\n",
    "\n",
    "This pipeline is used as the **initial processing step** prior to annotation, typing, and comparative genomics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d23fb7",
   "metadata": {},
   "source": [
    "## Cloning the Pipeline\n",
    "\n",
    "The GHRU assembly repository contains the Nextflow workflow for genome assembly. The pipeline was cloned from the official GitHub repository:\n",
    "\n",
    "https://github.com/ghruproject/GHRU-assembly\n",
    "\n",
    "The repository is cloned into a dedicated pipeline directory to keep workflow code separate from analysis outputs and notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d33ee42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "git clone https://github.com/ghruproject/GHRU-assembly.git \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f0c208d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "733404aaba789fad54ef942b3d4a036f11882ad5\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cd /home/nidhi/GHRU-assembly\n",
    "git rev-parse HEAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99d7c5c",
   "metadata": {},
   "source": [
    "The specific commit hash of the pipeline was recorded to ensure reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20974e17",
   "metadata": {},
   "source": [
    "## Tools Included in the Pipeline\n",
    "\n",
    "The GHRU assembly pipeline integrates multiple tools. The tools listed below directly correspond to the output directories generated by the pipeline.\n",
    "\n",
    "- **Trimmomatic**  \n",
    "  Used for adapter removal and quality trimming of raw Illumina paired-end reads. \n",
    "  Output directory:\n",
    "  - `trimmed_fastqs`\n",
    "\n",
    "- **FastQC**  \n",
    "  Used to assess sequencing read quality before and after trimming.  \n",
    "  Output directories:\n",
    "  - `qc_summary`\n",
    "  - `post_trimming_short_read_stats`\n",
    "\n",
    "- **Shovill (SPAdes)**  \n",
    "  Used for short-read genome assembly from trimmed Illumina reads.  \n",
    "  Output directory:\n",
    "  - `assemblies`\n",
    "\n",
    "- **QUAST**  \n",
    "  Used to evaluate assembly quality metrics such as genome length, number of contigs, and N50.  \n",
    "  Output directory:\n",
    "  - `quast_summary`\n",
    "\n",
    "- **Sylph**  \n",
    "  Used for k-mer–based species identification directly from sequencing reads.  \n",
    "  Output directory:\n",
    "  - `sylph_summary`\n",
    "\n",
    "- **SpecCheck**  \n",
    "  Used to validate and confirm species assignments generated by Sylph.  \n",
    "  Output directory:\n",
    "  - `speccheck`\n",
    "\n",
    "- **CheckM**  \n",
    "  Used to assess genome completeness and contamination of assembled genomes.  \n",
    "  Output directory:\n",
    "  - `checkm_summary`\n",
    "\n",
    "- **Species Classification (Sylph + SpecCheck)**  \n",
    "  Combined species-level assignment based on read-based prediction and validation.  \n",
    "  Output directory:\n",
    "  - `speciation_summary`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5cc73f",
   "metadata": {},
   "source": [
    "## Execution Metadata\n",
    "\n",
    "- **Pipeline:** GHRU assembly pipeline (Nextflow)\n",
    "- **Sequencing platform:** Illumina\n",
    "- **Read type:** Paired-end\n",
    "- **Assembly strategy:** Short-read assembly using Shovill (SPAdes backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce65245",
   "metadata": {},
   "source": [
    "## Input Files\n",
    "\n",
    "The pipeline requires a **CSV samplesheet** as input.\n",
    "\n",
    "### Samplesheet format\n",
    "\n",
    "The samplesheet must contain the following columns:\n",
    "\n",
    "- `sample_id` – Unique identifier for each sample  \n",
    "- `short_reads1` – Absolute path to forward reads (R1 FASTQ)  \n",
    "- `short_reads2` – Absolute path to reverse reads (R2 FASTQ)\n",
    "\n",
    "Each row corresponds to one sample.\n",
    "\n",
    "### Input Requirements\n",
    "\n",
    "- FASTQ files must be **paired-end Illumina reads**\n",
    "- File paths must be **absolute paths**\n",
    "- Sample IDs should not contain spaces or special characters\n",
    "- All input files must be readable by the execution environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcb8c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written:\n",
      "/data/internship_data/nidhi/aba/fastq_sheet.csv\n",
      "sample_id  short_reads1                                                     short_reads2\n",
      "ABA-1000   /data/internship_data/nidhi/aba/new_fastqs/ABA-1000_R1.fastq.gz  /data/internship_data/nidhi/aba/new_fastqs/ABA-1000_R2.fastq.gz\n",
      "ABA-1001   /data/internship_data/nidhi/aba/new_fastqs/ABA-1001_R1.fastq.gz  /data/internship_data/nidhi/aba/new_fastqs/ABA-1001_R2.fastq.gz\n",
      "ABA-1002   /data/internship_data/nidhi/aba/new_fastqs/ABA-1002_R1.fastq.gz  /data/internship_data/nidhi/aba/new_fastqs/ABA-1002_R2.fastq.gz\n",
      "ABA-1003   /data/internship_data/nidhi/aba/new_fastqs/ABA-1003_R1.fastq.gz  /data/internship_data/nidhi/aba/new_fastqs/ABA-1003_R2.fastq.gz\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Go to FASTQ folder\n",
    "cd /data/internship_data/nidhi/aba/new_fastqs\n",
    "\n",
    "# Create header\n",
    "echo \"sample_id,short_reads1,short_reads2\" > ../fastq_sheet.csv\n",
    "\n",
    "# Loop over common paired-end patterns: sample_1.fastq.gz or sample_R1.fastq.gz\n",
    "for r1 in *_1.fastq.gz *_1.fq.gz *_R1.fastq.gz *_R1.fq.gz; do\n",
    "  [ -e \"$r1\" ] || continue\n",
    "  # derive r2 name by replacing _1 with _2 or _R1 with _R2\n",
    "  if [[ \"$r1\" == *_1.* ]]; then\n",
    "    r2=\"${r1/_1./_2.}\"\n",
    "  else\n",
    "    r2=\"${r1/_R1./_R2.}\"\n",
    "  fi\n",
    "  [ -e \"$r2\" ] || { echo \"Warning: partner R2 not found for $r1\" >&2; continue; }\n",
    "  sample=$(echo \"$r1\" | sed -E 's/(_R?1).*//')   # remove the _1/_R1 and everything after\n",
    "  echo \"${sample},$(realpath \"$r1\"),$(realpath \"$r2\")\" >> ../fastq_sheet.csv\n",
    "done\n",
    "\n",
    "# Show resulting CSV\n",
    "echo \"Written:\" && realpath ../fastq_sheet.csv\n",
    "column -s, -t ../fastq_sheet.csv | sed -n '1,5p'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82810102",
   "metadata": {},
   "source": [
    "## Pipeline Execution\n",
    "\n",
    "The pipeline was executed within a Conda-managed environment. To avoid excessive runtime output in the Jupyter notebook, standard output and error streams were redirected to an external log file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9792b426",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# initialise conda\n",
    "source /home/anaconda/miniconda3/etc/profile.d/conda.sh\n",
    "conda activate nextflow\n",
    "\n",
    "# move into GHRU-assembly folder \n",
    "cd /home/nidhi/GHRU-assembly\n",
    "\n",
    "# command for execution\n",
    "nextflow run main.nf \\\n",
    "  --samplesheet /data/internship_data/nidhi/aba/fastq_sheet.csv \\\n",
    "  --outdir /data/internship_data/nidhi/aba/new_output/nextflow_output \\\n",
    "  > /data/internship_data/nidhi/aba/new_output/logs/nextflow.log 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a14cec",
   "metadata": {},
   "source": [
    "## Output Directory Structure\n",
    "\n",
    "The pipeline generates the following outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14e33f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assemblies\n",
      "checkm_summary\n",
      "post_trimming_short_read_stats\n",
      "qc_summary\n",
      "quast_summary\n",
      "speccheck\n",
      "speciation_summary\n",
      "sylph_summary\n",
      "trimmed_fastqs\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "ls /data/internship_data/nidhi/aba/new_output/nextflow_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfbeae7",
   "metadata": {},
   "source": [
    "All results are written to a dedicated output directory specified at runtime."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aba_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
